\section{Review of Network Based Approaches}

A number of approaches have been utilized to study networks in political science. Much of the early work of Maoz and Fowler simply sought to estimate the effects of network parameters within standard regression frameworks. However, as many have pointed out this without some correct for non-independence this approach is misguided and will lead to biased inferences. 

Second-order dependencies refer to what is often described as reciprocity in the context of directed relationships. Reciprocity is a not a new concept to the field of international studies; it has its roots in previous theories of cooperation and the evolution of norms between states \citep{richardson:1960,choucri:north:1972}. This concept has particular relevance in the conflict literature, as we would expect that if, for instance, Iran behaved aggressively towards Saudi Arabia that this would induce Saudi Arabia to behave aggressively in return. The prevalence of these types of potential interactions within directed dyadic data structures directly challenges the basic assumption of observational independence.

An example of a third-order dependency is transitivity, which follows the familiar logic of ``a friend of a friend is a friend''. The importance of these types of relationship is being increasingly recognized in the literature as well (see, for example, \citealp{lai:1995,manger:etal:2012,kinne:2013}). In binary data, transitivity describes the dependence among three actors $i$, $j$, $k$ in which $i$ and $j$ are more likely to be linked if linkages already exist between $i - k$ and $j - k$. The principal idea behind these dependencies is that knowing something about the relationships between $i-k$ and $j-k$ may reveal information about the relationship between $i-j$, even if it is not directly observed. This type of network dynamic might be particularly important for understanding the development of cooperative relationships. The consequence of not incorporating this type of dependency into our modeling framework is the same as above, and, as a result our models, will suffer from misspecification bias and will be more likely to result in type 1 errors. 

A common way to deal with this is the the multiple regression quadratic assignment procedure (MRQAP) introduced by \citet{krackhardt:1988} and refined by \citet{dekker:etal:2007}. The goal of the MRQAP procedure is different from ERGM based methods in that it focuses on examining the relationship between dyadic variables, whereas ERGM helps to examine relationships between dyadic variables and also accounts for structural tendencies in the network. A benefit of the MRQAP approach, however, is that it enables the study of weighted networks, whereas most implementations of ERGM based approaches are only developed for binary networks. The MRQAP and heteroscedasticity-consistent approaches are useful where research interest focuses exclusively on the effects of explanatory variables (`predictors', `covariates') and not on modeling the network as such or on structural dependencies. Conditionally uniform models are useful to provide a statistical control for a few relatively simple network dependencies while testing more complicated structural properties \citep{snijders:2011}. The MRQAP and heteroscedasticity-consistent approaches are useful, but are further not treated here because they regard network structure as nuisance rather than substance and do not attempt to model network dependencies. 

The third approach is to explicitly model the structural dependencies between tie variables. In contrast to the traditionally well known linear and generalized linear models which are the backbone of statistical modeling, such models need a potentially considerable number of parameters to express network structure, as we shall see below. This requires a change of vantage point for researchers because hypotheses may have to be formulated in terms not of relations between variables, such as the regression coefficients, correlation coefficients, or path coefficients of the more commonly used statistical models, but in terms of parameters representing more complex dependencies, such as transitive closure which is a dependency involving three variables at a time \citep{snijders:2011}.

However, the downside of the MRQAP is that it essentially treats the non-independence of observations in a network context as a nuisance that needs to just be corrected for. A number of alternative approaches have been developed that actually treat the network itself as an object of interest that needs to be studied. One of the most popular models for this kind of analysis in political science is the exponential random graph model (ERGM).

\citet{snijders:2001} developed an agent based approach, referred to as the stochastic actor-oriented model (SAOM), to modeling such binary networks that considers the linkages among the actors in terms of decisions, such that utility models could be implemented to generate the linkages. This strategy does enable the specification of a variety of network dynamics that may exist in the data, but the decision logic is homogeneous, with the same utility applying to each actor unless nodal covariates are specified. The SAOM technique has become a popular technique to modeling longitudinal networks in political science (e.g., see \citealp{manger:etal:2012, kinne:2013}). The temporal exponential random graph model (TERGM) developed by \citet{hanneke:xing:2007} and introduced to political science by \citet{cranmer:desmarais:2011} is a similar approach used to model binary longitudinal relational data. TERGM and SAOM share a similar mathematical core, the exponential random graph model (ERGM), but differ in their estimation approach and in how they deal with temporal dynamics \citep{leifeld:cranmer:2015}.  

\citet{hunter:etal:2008} % implementation of ergm
\citet{bhamidi:etal:2008} ... mcmc will onyl give good results of links are independent
\citet{chatterjee:diaconis:2013} ... 
\citet{shalizi:rinaldo:2013}
\citet{chandrasekhar:jackson:2014}
\citet{jackson:2014}
\citet{hunter:etal:2012}
While ERGMs are useful for modeling global network characteristics, models based on conditional independence (given latent variables) are useful for multiple reasons. First, ERGMs are not well- understood and sometimes possess undesirable properties, e.g., model degeneracy. Second, the likelihood function of ERGMs is intractable, complicating statistical computing. Third, there may be unobserved heterogeneity or unobserved structure.

Degeneracy is an indication of model mis-specification â€“ not a shortcoming of the MCMC estimation procedure. The solution to the degeneracy problem is to specify a model that is a better fit to the data, but this is often more difficult than usual. With linear models, for example, the estimated coefficients are linear functions of the observed data. These closed-form solutions can be used to construct predicted values, and mis-specification can be diagnosed by comparing observed to predicted values. With ERGMs, if the model is mis-specified and fails to produce an MLE, the analyst can be left with little information to help guide the re-specification of the model. A technique that commonly leads to degeneracy when representing dyad dependent processes is the use of simple configuration counts or proportions (e.g., the number of triangles or the mean clustering coefficient) as model covariates. It may seem natural to represent a disproportionately high number of triangles in a network by a triangle term in the model. But because a single edge can complete a large number of triangles, the dyadic dependence effects amplify quickly, so a model with a positive coefficient on a triangle term will almost always lead to degenerate behavior. This is a form of ``collapse'' or threshold behavior well known in complex systems \citep{handcock:etal:2008}.

For a longer discussion on model degeneracy at least when it comes to implementations in existing packages see \citet{handcock:2003b}. 